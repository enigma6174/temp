{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction To Classification\n",
    "<br>\n",
    "<p>In this example, we will be going through some basic classification techniques. Classification is s supervised machine learning task where instead of predicting a continous value (for eg. car price, house price etc.) we predict discontinuous values (or discrete values). These values can be any type and are genreally called as labels. Most of the common/popular examples include predicting labels of 2 types : yes/no or 0/1 or True/False.</p>\n",
    "<p>For eg. if we have an email dataset where we want to classify emails as SPAM or HAM then we have 2 labels: one label is SPAM and the other label is HAM. Similarly, if we have to predict breast cancer of 4 types (Type_1, Type_2, Type_3 and Type_4 breast cancer) then these 4 types could be considered as the labels.</p>\n",
    "<p>Classification of the second type(i.e. the second example) which involves more than 2 labels is called as multi-label classification whereas classification where we require 2 labels only is binary classification</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First, we start as importing the regular libraries popular in any machine learning project</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</p>After importing the basic set of libraries, we set some of the parameters of the functions which will be useful later on in the code. Read the comments above the code to understand what is being done.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters that control the size of the axes and the x and y labels in the plots\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# the folders where we will save the relevant output of our code\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"chapter_3\"\n",
    "IMAGE_PATH = os.path.join(PROJECT_ROOT_DIR, CHAPTER_ID, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</p>Define a function to save the images in a new folder in the directory `chapter_3\\images\\` and the image name will be taken from the figure id (a number to identify the plot) and saved as a `PNG` file.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The `os.path.join()` function creates a path by combining the parameters passed to it. If the last parameter passed is an extension (see code below) then it saves a file. For more information on `os.path.join()` [cick here.](https://stackoverflow.com/questions/20645420/how-does-os-path-join-work)</p>\n",
    "<p>The `tight_layout` option makes subplots within a plot look nice and evenly spaced. It adds some space between two plots so that their axes are readable. For more information on how `tight_layout` works [click here.](https://stackoverflow.com/questions/9603230/how-to-use-matplotlib-tight-layout-with-figure) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tight_layout to True because we want our plots to look nice and clean\n",
    "def save_fig(fig_id, tight_layout = True, fig_extension='png', resolution=360):\n",
    "    \n",
    "    # returns a string of the path where we need to save the image file(s).\n",
    "    path = os.path.join(IMAGE_PATH, fig_id + '.' + fig_extension)\n",
    "    \n",
    "    # create a directory if the default image directory does not exist\n",
    "    if not os.path.isdir(IMAGE_PATH):\n",
    "        os.makedirs(IMAGE_PATH)\n",
    "        \n",
    "    # sometimes it is good to print a message; image plotting can be slow and time consuming sometimes\n",
    "    # best tell user what the code is doing or the user might be fooled into thinking the code crashed\n",
    "    print(\"Saving figure....\", fig_id)\n",
    "    \n",
    "    # plot the figure (with tight layout)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # save the figure in the path specified earlier in png format\n",
    "    plt.savefig(path, format=fig_extension, dpi = 360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The MNIST dataset is considered as the _hello world_ program of classification in machine learning. It is a collection of 70,000 images of handwritten digits from 0 to 9 by people of various age groups. Any classification model that we build, we would always like to test it out on the MNIST dataset to see how it performs.</p>\n",
    "<p>Thankfully, _scikit-learn_ makes it easy for us to access the MNIST dataset. It consists of many pre-loaded datasets that we can call anytime. The same goes for MNIST dataset. We can directly load the mnist dataset from _scikit-learn._</p>\n",
    "<p>The MNIST dataset is already divided into train-set and test-set so we won't have to go through the trouble of splitting the data into train and test sets. We do however, need to sort the MNIST dataset _scikit-learn_ returns the MNIST dataset in unordered form. For more information on the MNIST dataset [click here](http://yann.lecun.com/exdb/mnist/).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>However, before we proceed let us first create a function which sorts the MNIST dataset. I will describe the MNIST dataset below so let us first walk throught the function and then understand what the dataset looks like. On a side note, the `target` attribute of any dataset in `sklearn` consists of an array of labels, in this case the `target` is an array consisting of the labels of the images.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function which takes the MNIST dataset as parameter\n",
    "def sort_by_target(mnist):\n",
    "    \n",
    "    # a numpy array which stores the sorted target labels from 0 to 9\n",
    "    # the values are first enumerated and then the (target, enumeration) pair is sorted\n",
    "    # the first sorting is done on target key and after sorting on target values, the sorting is done on enumeration\n",
    "    # the process is the same for train and test sets\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:,1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:,1]\n",
    "    \n",
    "    # reorder the first 60000 entries in the mnist dataset that was passed to us using indices obtained above\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    # similar logic as above is applied for reordering the target array \n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    \n",
    "    # the indices from 60000 to 70000 in the original dataset represented test data\n",
    "    # to reorder the original test data indices we add 60000 to to the reordered test array\n",
    "    # this gives us indices from 60000 to 70000\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that the function to sort the MNIST dataset is defined properly, time to load the dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([0, 0, 0, ..., 9, 9, 9], dtype=int8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the required library for MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# specify the MNIST dataset to load in the library; it contains other datasets also\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "\n",
    "# sklearn returns the target column as strings; we need integers; convert to int\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "\n",
    "# sort the mnist dataset by target attribute\n",
    "sort_by_target(mnist)\n",
    "\n",
    "# display the dataset\n",
    "mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About The Dataset\n",
    "\n",
    "<p> The MNIST dataset as mentioned earlier, contains a collection of 70000 handwritten images of digits from 0 to 9. These images are 28px by 28px which means they are 28 pixels wide and 28 pixels high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X matrix and y label vector from the mnist dataset\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X :  (70000, 784)\n",
      "shape of Y :  (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X : \", X.shape)\n",
    "print(\"shape of Y : \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure.... some_digit_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grab some random digit from the training set X\n",
    "some_digit = X[36000]\n",
    "\n",
    "# reshape the digit to original specifications ie. 28x28\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "# plot the image\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation='nearest')\n",
    "plt.axis('on')\n",
    "\n",
    "# save the figure\n",
    "save_fig('some_digit_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the above logic create a function to plot any digit\n",
    "def plot_digit(data, save=False):\n",
    "    \n",
    "    # reshape the data into a 28x28 matrix\n",
    "    image = data.reshape(28, 28)\n",
    "    \n",
    "    # plot the image\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation='nearest')\n",
    "    plt.axis('on')\n",
    "    \n",
    "    # if the save paramter is True, save the image\n",
    "    # by default, the save parameter has been set to False\n",
    "    if save is True:\n",
    "        \n",
    "        print(\"saving the figure...\")\n",
    "        \n",
    "        # import datetime library\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # get the current time and convert to string\n",
    "        # only extract minute, second and micro-seconds\n",
    "        # this will be enough to ensure a unique file-name for saving the image\n",
    "        x = datetime.now().time()\n",
    "        x = x.strftime(\"%M%S%f\")\n",
    "        \n",
    "        # save the figure with unique name\n",
    "        save_fig('random_image' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X[36000]\n",
    "plot_digit(some_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "example_images = np.r_[X[:12000:600], X[13000:30600:600], X[30600:60000:590]]\n",
    "plot_digits(example_images, images_per_row=10)\n",
    "save_fig(\"more_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test dataset\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It is important to shuffle the train set so as to randomize the entries. This applies to both the training set and the labels corresponding to the training set. A randomized order of elements ensure that the model does not learn the inherent pattern as a consequence of ordered nature of the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "<p>Here I will first attempt to perform classification on a binary classifier, ie. I will check if a given digit is a 5 or not. For that, the only extra thing we need is a set of labels containing 1 to represent 5 and 0 for everything else.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Note:</b> Some of the hyperparameters in Scikit-Learn libraries have to be set exlpicitly or they will generate a warning message. To avoid the warnings the hyperparameters have been set to their given values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=-inf,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9187 ,  0.95185,  0.9459 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
